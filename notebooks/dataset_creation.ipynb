{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cards Dataset length = 97145\n",
      "Prices Dataset length = 558079 \n",
      "\n",
      "Cards Columns Num = 25\n",
      "Price Columns Num = 8\n",
      "\n",
      "Cards length by UUID = 97145\n",
      "Prices length by UUID= 91302\n",
      "\n",
      "Num of unique dates = 1\n",
      "Price Date = 2024-09-20\n"
     ]
    }
   ],
   "source": [
    "cards_csv = pd.read_csv('../dataset/cards.csv', sep=\";\")\n",
    "prices_csv = pd.read_csv('../dataset/cardPrices.csv', sep=\",\")\n",
    "\n",
    "print(f\"Cards Dataset length = {len(cards_csv)}\")\n",
    "print(f\"Prices Dataset length = {len(prices_csv)} \\n\")\n",
    "\n",
    "print(f\"Cards Columns Num = {cards_csv.shape[1]}\")\n",
    "print(f\"Price Columns Num = {prices_csv.shape[1]}\\n\")\n",
    "\n",
    "# number of unique dataset instances by uuid\n",
    "card_unique = cards_csv['uuid'].nunique()\n",
    "price_unique = prices_csv['uuid'].nunique()\n",
    "\n",
    "print(f\"Cards length by UUID = {card_unique}\")\n",
    "print(f\"Prices length by UUID= {price_unique}\\n\")\n",
    "\n",
    "dates = prices_csv['date'].nunique()\n",
    "date = prices_csv['date'][0]\n",
    "print(f\"Num of unique dates = {dates}\")\n",
    "print(f\"Price Date = {date}\")\n",
    "\n",
    "#print(cards_csv.nunique())\n",
    "#print(prices_csv.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = cards_csv\n",
    "prices = prices_csv\n",
    "\n",
    "# Drop columns that are duplicates\n",
    "cards = cards.drop(columns=['finishes'])\n",
    "cards = cards.drop(columns=['hasFoil'])\n",
    "cards = cards.drop(columns=['hasNonFoil'])\n",
    "cards = cards.drop(columns=['sourceProducts'])\n",
    "\n",
    "# Drop constant columns\n",
    "prices = prices[prices['currency'] == 'USD']\n",
    "prices = prices.drop(columns=['currency'])\n",
    "prices = prices.drop(columns=['date'])\n",
    "\n",
    "# Standardize colors and colorIdentity\n",
    "def unique_colors(value):\n",
    "    if pd.isna(value):\n",
    "        return None  # Return None for NaN\n",
    "    # Split the value, standardize, and get unique characters\n",
    "    characters = set(', '.join(sorted(value.split(', '))).replace(', ', ''))\n",
    "    return ''.join(sorted(characters))\n",
    "\n",
    "# Apply the function to the columns\n",
    "cards['colors'] = cards['colors'].apply(unique_colors)\n",
    "cards['colorIdentity'] = cards['colorIdentity'].apply(unique_colors)\n",
    "\n",
    "# replace NaN values with False\n",
    "cards.loc[cards['isReprint'].isna(), \"isReprint\"] = False\n",
    "# Map True to 1 and False to 0\n",
    "cards['isReprint'] = cards['isReprint'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cards2 is going to be used in secondary\n",
    "cards2 = cards.copy()\n",
    "\n",
    "cards2['colors'] = cards2['colors'].fillna('C')\n",
    "cards2['colorIdentity'] = cards2['colorIdentity'].fillna('C')\n",
    "\n",
    "cards2['originalType'] = cards2['originalType'].fillna('None')\n",
    "cards2['power'] = cards2['power'].fillna('None')\n",
    "cards2['supertypes'] = cards2['supertypes'].fillna('None')\n",
    "cards2['toughness'] = cards2['toughness'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary dataset by uuid (cards with prices) size: 17628\n",
      "Seconday dataset by uuid (cards with prices) size: 269807\n"
     ]
    }
   ],
   "source": [
    "# perform inner join based on UUID, then drop null values\n",
    "primary = pd.merge(prices, cards, on=\"uuid\")\n",
    "primary = primary.dropna().reset_index(drop=True)\n",
    "print(f\"Primary dataset by uuid (cards with prices) size: {len(primary)}\")\n",
    "\n",
    "\n",
    "secondary = pd.merge(prices, cards2, on=\"uuid\")\n",
    "secondary = secondary.dropna().reset_index(drop=True)\n",
    "print(f\"Seconday dataset by uuid (cards with prices) size: {len(secondary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary.to_csv('../dataset/primary.csv', index = False)\n",
    "secondary.to_csv('../dataset/secondary.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
