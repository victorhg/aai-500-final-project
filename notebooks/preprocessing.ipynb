{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cards Dataset length = 97145\n",
      "Prices Dataset length = 558079 \n",
      "\n",
      "Cards Columns Num = 25\n",
      "Price Columns Num = 8\n",
      "\n",
      "Cards length by UUID = 97145\n",
      "Prices length by UUID= 91302\n",
      "\n",
      "Num of unique dates = 1\n",
      "Price Date = 2024-09-20\n"
     ]
    }
   ],
   "source": [
    "cards_csv = pd.read_csv('../dataset/cards.csv', sep=\";\")\n",
    "prices_csv = pd.read_csv('../dataset/cardPrices.csv', sep=\",\")\n",
    "\n",
    "print(f\"Cards Dataset length = {len(cards_csv)}\")\n",
    "print(f\"Prices Dataset length = {len(prices_csv)} \\n\")\n",
    "\n",
    "print(f\"Cards Columns Num = {cards_csv.shape[1]}\")\n",
    "print(f\"Price Columns Num = {prices_csv.shape[1]}\\n\")\n",
    "\n",
    "# number of unique dataset instances by uuid\n",
    "card_unique = cards_csv['uuid'].nunique()\n",
    "price_unique = prices_csv['uuid'].nunique()\n",
    "\n",
    "print(f\"Cards length by UUID = {card_unique}\")\n",
    "print(f\"Prices length by UUID= {price_unique}\\n\")\n",
    "\n",
    "dates = prices_csv['date'].nunique()\n",
    "date = prices_csv['date'][0]\n",
    "print(f\"Num of unique dates = {dates}\")\n",
    "print(f\"Price Date = {date}\")\n",
    "\n",
    "#print(cards_csv.nunique())\n",
    "#print(prices_csv.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = cards_csv\n",
    "prices = prices_csv\n",
    "\n",
    "# Drop columns that are duplicates\n",
    "cards = cards.drop(columns=['finishes'])\n",
    "cards = cards.drop(columns=['hasFoil'])\n",
    "cards = cards.drop(columns=['hasNonFoil'])\n",
    "cards = cards.drop(columns=['sourceProducts'])\n",
    "\n",
    "# Drop constant columns\n",
    "prices = prices[prices['currency'] == 'USD']\n",
    "prices = prices.drop(columns=['currency'])\n",
    "prices = prices.drop(columns=['date'])\n",
    "\n",
    "# Standardize colors and colorIdentity\n",
    "def unique_colors(value):\n",
    "    if pd.isna(value):\n",
    "        return None  # Return None for NaN\n",
    "    # Split the value, standardize, and get unique characters\n",
    "    characters = set(', '.join(sorted(value.split(', '))).replace(', ', ''))\n",
    "    return ''.join(sorted(characters))\n",
    "\n",
    "# Apply the function to the columns\n",
    "cards['colors'] = cards['colors'].apply(unique_colors)\n",
    "cards['colorIdentity'] = cards['colorIdentity'].apply(unique_colors)\n",
    "\n",
    "# replace NaN values with False\n",
    "cards.loc[cards['isReprint'].isna(), \"isReprint\"] = False\n",
    "# Map True to 1 and False to 0\n",
    "cards['isReprint'] = cards['isReprint'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cards2 is going to be used in secondary\n",
    "cards2 = cards.copy()\n",
    "\n",
    "cards2['colors'] = cards2['colors'].fillna('C')\n",
    "cards2['colorIdentity'] = cards2['colorIdentity'].fillna('C')\n",
    "\n",
    "cards2['originalType'] = cards2['originalType'].fillna('None')\n",
    "cards2['power'] = cards2['power'].fillna('None')\n",
    "cards2['supertypes'] = cards2['supertypes'].fillna('None')\n",
    "cards2['toughness'] = cards2['toughness'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary dataset by uuid (cards with prices) size: 17628\n",
      "Seconday dataset by uuid (cards with prices) size: 269807\n"
     ]
    }
   ],
   "source": [
    "# perform inner join based on UUID, then drop null values\n",
    "primary = pd.merge(prices, cards, on=\"uuid\")\n",
    "primary = primary.dropna().reset_index(drop=True)\n",
    "print(f\"Primary dataset by uuid (cards with prices) size: {len(primary)}\")\n",
    "\n",
    "\n",
    "secondary = pd.merge(prices, cards2, on=\"uuid\")\n",
    "secondary = secondary.dropna().reset_index(drop=True)\n",
    "print(f\"Seconday dataset by uuid (cards with prices) size: {len(secondary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num outliers: 2414\n",
      "Num outliers: 41170\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers by prices\n",
    "def removeOutliers(data, col):\n",
    "    Q3 = np.quantile(data[col], 0.75)\n",
    "    Q1 = np.quantile(data[col], 0.25)\n",
    "    IQR = Q3 - Q1\n",
    " \n",
    "    lower_range = Q1 - 1.5 * IQR\n",
    "    upper_range = Q3 + 1.5 * IQR\n",
    "    outlier_free_list = [x for x in data[col] if ((x > lower_range) & (x < upper_range))]\n",
    "    print(f\"Num outliers: {len(data) - len(outlier_free_list)}\")\n",
    "    filtered_data = data.loc[data[col].isin(outlier_free_list)]\n",
    "    return filtered_data\n",
    "\n",
    "# data no outliers\n",
    "primary = removeOutliers(primary, 'price')\n",
    "secondary = removeOutliers(secondary, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_categorical(data):\n",
    "    numerical_data = pd.DataFrame()\n",
    "    categorical_data = pd.DataFrame()\n",
    "    mapping_dict = {}\n",
    "\n",
    "    # columns to encode\n",
    "    to_encode = ['rarity', 'artist', 'cardFinish', 'supertypes', 'type',\n",
    "                 'gameAvailability', 'priceProvider', 'setCode', 'types',\n",
    "                 'colors', 'colorIdentity', 'layout', 'language',\n",
    "                 'power', 'toughness', 'manaCost', 'name', 'number',\n",
    "                 'originalType']\n",
    "    # non encoded columns uuid (54855)\n",
    "\n",
    "    # first map binary data\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'float64' or data[col].dtype == 'int64':\n",
    "            numerical_data[col] = data[col]\n",
    "        elif data[col].dtype == 'object' or isinstance(data[col].dtype, pd.CategoricalDtype):\n",
    "            unique_values = data[col].unique()\n",
    "            if len(unique_values) == 2:\n",
    "                # creating mapping to use later\n",
    "                mapping = {unique_values[0]: 0, unique_values[1]: 1}\n",
    "                mapping_dict[col] = mapping\n",
    "\n",
    "                # Replace the values in the binary DataFrame\n",
    "                numerical_data[col] = data[col].map(mapping)\n",
    "            else:\n",
    "                categorical_data[col] = data[col]\n",
    "        else:\n",
    "            categorical_data[col] = data[col]\n",
    "        \n",
    "    # map other categorical columns \n",
    "    for col in categorical_data.columns:\n",
    "        if col in to_encode:\n",
    "            numerical_data[col] = categorical_data[col].astype('category').cat.codes\n",
    "            mapping_dict[col] = {category: code for category, code in zip(categorical_data[col].astype('category').cat.categories, range(len(categorical_data[col].astype('category').cat.categories)))}\n",
    "            categorical_data = categorical_data.drop(columns=[col])\n",
    "        \n",
    "        if col == 'uuid':\n",
    "            numerical_data[col] = categorical_data[col]\n",
    "            \n",
    "    return numerical_data, categorical_data, mapping_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Columns mapped example: {'common': 0, 'mythic': 1, 'rare': 2, 'special': 3, 'uncommon': 4}\n",
      "Secondary columns mapped example: {'bonus': 0, 'common': 1, 'mythic': 2, 'rare': 3, 'special': 4, 'uncommon': 5}\n",
      "\n",
      "Primary Categorical data excluded: ['uuid']\n",
      "Secondary Categorical data excluded: ['uuid']\n"
     ]
    }
   ],
   "source": [
    "numerical_primary, categorical_primary, mapping_primary = map_categorical(primary)\n",
    "numerical_secondary, categorical_secondary, mapping_secondary = map_categorical(secondary)\n",
    "\n",
    "print(f\"Primary Columns mapped example: {mapping_primary['rarity']}\")\n",
    "print(f\"Secondary columns mapped example: {mapping_secondary['rarity']}\\n\")\n",
    "\n",
    "print(f\"Primary Categorical data excluded: {categorical_primary.columns.tolist()}\")\n",
    "print(f\"Secondary Categorical data excluded: {categorical_secondary.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframes\n",
    "order = ['price'] + sorted([col for col in numerical_primary.columns if col != 'price'])\n",
    "numerical_primary = numerical_primary[order]\n",
    "numerical_secondary = numerical_secondary[order]\n",
    "numerical_primary = numerical_primary.drop(columns=['language'])\n",
    "\n",
    "# save out mapped data + uuid to same file\n",
    "numerical_primary.to_csv('../dataset/mapped_primary.csv', index = False)\n",
    "numerical_secondary.to_csv('../dataset/mapped_secondary.csv', index = False)\n",
    "\n",
    "json.dump(mapping_primary, open('../dataset/mapping_primary.json', 'w'))\n",
    "json.dump(mapping_secondary, open('../dataset/mapping_secondary.json', 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Dataset length = 15214\n",
      "Secondary Dataset length = 228637 \n",
      "\n",
      "Primary Columns Num = 25\n",
      "Secondary Columns Num = 26\n",
      "\n",
      "Primary length by UUID = 3123\n",
      "Prices length by UUID= 50208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Primary Dataset length = {len(numerical_primary)}\")\n",
    "print(f\"Secondary Dataset length = {len(numerical_secondary)} \\n\")\n",
    "\n",
    "print(f\"Primary Columns Num = {numerical_primary.shape[1]}\")\n",
    "print(f\"Secondary Columns Num = {numerical_secondary.shape[1]}\\n\")\n",
    "\n",
    "# number of unique dataset instances by uuid\n",
    "primary_unique = numerical_primary['uuid'].nunique()\n",
    "secondary_unique = numerical_secondary['uuid'].nunique()\n",
    "\n",
    "print(f\"Primary length by UUID = {primary_unique}\")\n",
    "print(f\"Prices length by UUID= {secondary_unique}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Columns Num = ['price', 'artist', 'cardFinish', 'colorIdentity', 'colors', 'edhrecRank', 'edhrecSaltiness', 'gameAvailability', 'isReprint', 'layout', 'manaCost', 'manaValue', 'name', 'number', 'originalType', 'power', 'priceProvider', 'providerListing', 'rarity', 'setCode', 'supertypes', 'toughness', 'type', 'types', 'uuid']\n",
      "Secondary Columns Num = ['price', 'artist', 'cardFinish', 'colorIdentity', 'colors', 'edhrecRank', 'edhrecSaltiness', 'gameAvailability', 'isReprint', 'language', 'layout', 'manaCost', 'manaValue', 'name', 'number', 'originalType', 'power', 'priceProvider', 'providerListing', 'rarity', 'setCode', 'supertypes', 'toughness', 'type', 'types', 'uuid']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Primary Columns Num = {numerical_primary.columns.tolist()}\")\n",
    "print(f\"Secondary Columns Num = {numerical_secondary.columns.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
